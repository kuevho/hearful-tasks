{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of tasks\n",
    "- evaluate the performance of the model on the following metrics\n",
    "    - precision\n",
    "    - recall\n",
    "    - accuracy\n",
    "    - f-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import files\n",
    "df_hv = pd.read_csv('APPAREL_ODOM_1_2019.csv')\n",
    "\n",
    "df_pm = pd.read_csv('APPAREL_ids_1_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298 entries, 0 to 297\n",
      "Data columns (total 16 columns):\n",
      "_id                        298 non-null object\n",
      "domain_global_string       298 non-null object\n",
      "review_rating              298 non-null int64\n",
      "notes                      97 non-null object\n",
      "review_text                298 non-null object\n",
      "review_title               278 non-null object\n",
      "use_sentiment_label        110 non-null object\n",
      "use_theme_exists           298 non-null int64\n",
      "fit_sentiment_label        209 non-null object\n",
      "fit_theme_exists           298 non-null int64\n",
      "value_sentiment_label      101 non-null object\n",
      "value_theme_exists         298 non-null int64\n",
      "style_sentiment_label      120 non-null object\n",
      "style_theme_exists         298 non-null int64\n",
      "quality_sentiment_label    189 non-null object\n",
      "quality_theme_exists       297 non-null float64\n",
      "dtypes: float64(1), int64(5), object(10)\n",
      "memory usage: 37.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#check ground truth\n",
    "df_hv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 15 columns):\n",
      "_id                        300 non-null object\n",
      "domain_global_string       300 non-null object\n",
      "review_rating              300 non-null int64\n",
      "review_text                300 non-null object\n",
      "review_title               278 non-null object\n",
      "use_sentiment_label        146 non-null object\n",
      "use_theme_exists           156 non-null float64\n",
      "fit_sentiment_label        220 non-null object\n",
      "fit_theme_exists           226 non-null float64\n",
      "value_sentiment_label      93 non-null object\n",
      "value_theme_exists         99 non-null float64\n",
      "style_sentiment_label      180 non-null object\n",
      "style_theme_exists         183 non-null float64\n",
      "quality_sentiment_label    201 non-null object\n",
      "quality_theme_exists       215 non-null float64\n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 35.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#check predictive model\n",
    "#note that they do not match number of entries\n",
    "df_pm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find missing entries in predictive model and remove them\n",
    "df12 = pd.merge(df_hv, df_pm, on='_id', how='inner')     #extract common rows with merge\n",
    "df2 = df_pm[~df_pm['_id'].isin(df12['_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 _id domain_global_string  review_rating  \\\n",
      "287  walmart79904828              APPAREL              5   \n",
      "297    zappos5307009              APPAREL              5   \n",
      "\n",
      "                                           review_text review_title  \\\n",
      "287  We have tried this product for the last week a...          NaN   \n",
      "297  I was traveling through Seoul, South Korea whe...          NaN   \n",
      "\n",
      "    use_sentiment_label  use_theme_exists fit_sentiment_label  \\\n",
      "287                 NaN               NaN                 pos   \n",
      "297                 NaN               1.0                 pos   \n",
      "\n",
      "     fit_theme_exists value_sentiment_label  value_theme_exists  \\\n",
      "287               1.0                   NaN                 NaN   \n",
      "297               1.0                   neg                 1.0   \n",
      "\n",
      "    style_sentiment_label  style_theme_exists quality_sentiment_label  \\\n",
      "287                   NaN                 NaN                     NaN   \n",
      "297                   pos                 1.0                     pos   \n",
      "\n",
      "     quality_theme_exists  \n",
      "287                   1.0  \n",
      "297                   1.0  \n"
     ]
    }
   ],
   "source": [
    "#check missing entries\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>domain_global_string</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_title</th>\n",
       "      <th>use_sentiment_label</th>\n",
       "      <th>use_theme_exists</th>\n",
       "      <th>fit_sentiment_label</th>\n",
       "      <th>fit_theme_exists</th>\n",
       "      <th>value_sentiment_label</th>\n",
       "      <th>value_theme_exists</th>\n",
       "      <th>style_sentiment_label</th>\n",
       "      <th>style_theme_exists</th>\n",
       "      <th>quality_sentiment_label</th>\n",
       "      <th>quality_theme_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>walmart79904828</td>\n",
       "      <td>APPAREL</td>\n",
       "      <td>5</td>\n",
       "      <td>We have tried this product for the last week a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id domain_global_string  review_rating  \\\n",
       "287  walmart79904828              APPAREL              5   \n",
       "\n",
       "                                           review_text review_title  \\\n",
       "287  We have tried this product for the last week a...          NaN   \n",
       "\n",
       "    use_sentiment_label  use_theme_exists fit_sentiment_label  \\\n",
       "287                 NaN               NaN                 pos   \n",
       "\n",
       "     fit_theme_exists value_sentiment_label  value_theme_exists  \\\n",
       "287               1.0                   NaN                 NaN   \n",
       "\n",
       "    style_sentiment_label  style_theme_exists quality_sentiment_label  \\\n",
       "287                   NaN                 NaN                     NaN   \n",
       "\n",
       "     quality_theme_exists  \n",
       "287                   1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm that missing entries from ground truth is in fact in predictive model before removing them\n",
    "df_pm.loc[df_pm['_id'] == 'walmart79904828']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove entries from predictive model that isn't in ground truth\n",
    "df_pm = df_pm[df_pm['_id'] != 'walmart79904828']\n",
    "\n",
    "df_pm = df_pm[df_pm['_id'] != 'zappos5307009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 298 entries, 0 to 299\n",
      "Data columns (total 15 columns):\n",
      "_id                        298 non-null object\n",
      "domain_global_string       298 non-null object\n",
      "review_rating              298 non-null int64\n",
      "review_text                298 non-null object\n",
      "review_title               278 non-null object\n",
      "use_sentiment_label        146 non-null object\n",
      "use_theme_exists           155 non-null float64\n",
      "fit_sentiment_label        218 non-null object\n",
      "fit_theme_exists           224 non-null float64\n",
      "value_sentiment_label      92 non-null object\n",
      "value_theme_exists         98 non-null float64\n",
      "style_sentiment_label      179 non-null object\n",
      "style_theme_exists         182 non-null float64\n",
      "quality_sentiment_label    200 non-null object\n",
      "quality_theme_exists       213 non-null float64\n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 37.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#check to confirm that we have the same number of entries\n",
    "df_pm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fmeasures</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>theme_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.781879</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.859060</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.862416</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.657718</td>\n",
       "      <td>0.662252</td>\n",
       "      <td>0.549451</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798658</td>\n",
       "      <td>0.849246</td>\n",
       "      <td>0.793427</td>\n",
       "      <td>0.913514</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  fmeasures  precision    recall theme_exists\n",
       "0  0.781879   0.754717   0.645161  0.909091          use\n",
       "1  0.859060   0.901408   0.857143  0.950495          fit\n",
       "2  0.862416   0.787565   0.775510  0.800000        value\n",
       "3  0.657718   0.662252   0.549451  0.833333        style\n",
       "4  0.798658   0.849246   0.793427  0.913514      quality"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find metrics for theme_exists\n",
    "themes = [ 'use', 'fit', 'value', 'style', 'quality']\n",
    "theme_exists = []\n",
    "for t in themes:\n",
    "    c1 = t + '_theme_exists'\n",
    "    y_true = df_hv[c1].fillna( 0. )\n",
    "    y_pred = df_pm[c1].fillna ( 0. )\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    fmeasure = f1_score(y_true, y_pred)\n",
    "    theme_exist = {\n",
    "        'theme_exists':t,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'accuracy':accuracy, \n",
    "        'fmeasures':fmeasure, \n",
    "    }\n",
    "    theme_exists.append( theme_exist )\n",
    "df3 = pd.DataFrame( theme_exists )\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some reason I can't put this in a loop without messing up my metrics loop so here it is in all its glory\n",
    "#copyandpaste\n",
    "#change string to float\n",
    "sent_map = {'pos':1, 'neg':2}\n",
    "df_hv['use_sentiment_label'] = df_hv['use_sentiment_label'].map(sent_map)\n",
    "df_hv['fit_sentiment_label'] = df_hv['fit_sentiment_label'].map(sent_map)\n",
    "df_hv['value_sentiment_label'] = df_hv['value_sentiment_label'].map(sent_map)\n",
    "df_hv['style_sentiment_label'] = df_hv['style_sentiment_label'].map(sent_map)\n",
    "df_hv['quality_sentiment_label'] = df_hv['quality_sentiment_label'].map(sent_map)\n",
    "\n",
    "df_pm['use_sentiment_label'] = df_pm['use_sentiment_label'].map(sent_map)\n",
    "df_pm['fit_sentiment_label'] = df_pm['fit_sentiment_label'].map(sent_map)\n",
    "df_pm['value_sentiment_label'] = df_pm['value_sentiment_label'].map(sent_map)\n",
    "df_pm['style_sentiment_label'] = df_pm['style_sentiment_label'].map(sent_map)\n",
    "df_pm['quality_sentiment_label'] = df_pm['quality_sentiment_label'].map(sent_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if I put this in a loop, I get whack metric numbers once I fill nas\n",
    "#copyandpaste\n",
    "#wonder what i'm doing wrong here...\n",
    "df_hv['use_sentiment_label'] = df_hv['use_sentiment_label'].fillna( 0. )\n",
    "df_hv['fit_sentiment_label'] = df_hv['fit_sentiment_label'].fillna( 0. )\n",
    "df_hv['value_sentiment_label'] = df_hv['value_sentiment_label'].fillna( 0. )\n",
    "df_hv['style_sentiment_label'] = df_hv['style_sentiment_label'].fillna( 0. )\n",
    "df_hv['quality_sentiment_label'] = df_hv['quality_sentiment_label'].fillna( 0. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm['use_sentiment_label'] = df_pm['use_sentiment_label'].fillna( 0. )\n",
    "df_pm['fit_sentiment_label'] = df_pm['fit_sentiment_label'].fillna( 0. )\n",
    "df_pm['value_sentiment_label'] = df_pm['value_sentiment_label'].fillna( 0. )\n",
    "df_pm['style_sentiment_label'] = df_pm['style_sentiment_label'].fillna( 0. )\n",
    "df_pm['quality_sentiment_label'] = df_pm['quality_sentiment_label'].fillna( 0. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>fmeasures</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>theme_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>0.805369</td>\n",
       "      <td>fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.838926</td>\n",
       "      <td>0.838926</td>\n",
       "      <td>0.838926</td>\n",
       "      <td>0.838926</td>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.634228</td>\n",
       "      <td>0.634228</td>\n",
       "      <td>0.634228</td>\n",
       "      <td>0.634228</td>\n",
       "      <td>style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  fmeasures  precision    recall theme_sentiment\n",
       "0  0.765101   0.765101   0.765101  0.765101             use\n",
       "1  0.805369   0.805369   0.805369  0.805369             fit\n",
       "2  0.838926   0.838926   0.838926  0.838926           value\n",
       "3  0.634228   0.634228   0.634228  0.634228           style\n",
       "4  0.664430   0.664430   0.664430  0.664430         quality"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my familar loop to find the metrics for theme_sentiment\n",
    "themes = [ 'use', 'fit', 'value', 'style', 'quality']\n",
    "theme_sentiments = []\n",
    "\n",
    "for t in themes:\n",
    "    c2 = t + '_sentiment_label'\n",
    "    y_true = df_hv[c2]\n",
    "    y_pred = df_pm[c2]\n",
    "    precision = precision_score(y_true, y_pred, average = 'micro')\n",
    "    recall = recall_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    fmeasure = f1_score(y_true, y_pred, average = 'micro')\n",
    "    theme_sentiment = {\n",
    "        'theme_sentiment':t,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'accuracy':accuracy, \n",
    "        'fmeasures':fmeasure, \n",
    "    }\n",
    "    theme_sentiments.append( theme_sentiment )\n",
    "df4 = pd.DataFrame( theme_sentiments )\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
